واریانس و همبستگی
========================
## واریانس
بگذارید ابتدا مثالی برای شروع طرح کنیم نمودار های زیر که اعداد نوشته شده به رنگ قرمز احتمال رخ دادن آن مقدار است را ببینید.
تصویر 1
در تمام نمودار ها امید ریاضی برابر 0 می باشد. چه چیزی در این PMF ها متفاوت است؟
به نوعی فاصله متغیر تصادفی ها از امید ریاضی آنها متفاوت است یا به نوعی هر کدام به ما می گویند که چقدر می توانند از امید ریاضی شان دور شوند.
در شکل بالا همانطور که مشاهده میشود نمودار A دارای واریانس صفر است یا به نوعی تمام وزنش در میانگینش قرار گرفته و نمودار C دارای بیشترین واریانس بین این سه نمودار است و B هم واریانسی بین این دو مقدار دارد.
```{admonition} احتیاط!
:class: warning
نمودار C بیشترین واریانس بین تمام تموزیع های ممکن با امید ریاضی صفر را ندارد! بلکه بیشترین بی نظمی(آنتروپی) را دارد.  
(مفهوم آنتروپی در این درس مورد بررسی نبوده!)  
مثلا توزیع زیر واریانسی بیشتر از نمودار C دارد.  
تصویر 2
```
حال رابطه ریاضی واریانس را بررسی کنیم.
$$Var(X) =E[(X-E(X))^{2}]$$
بنظر شما چرا کل این عبارت توان دو دارد؟
بله همانطور که متوجه شدید واریانس به نوعی مفهوم فاصله از یک نقطه(میانگین) است پس اگر به توان دو نمی رسید میتوان حدس زد مقدار عبارت مورد نظر 0 می شد زیرا $$E(X)$$ یک عدد ثابت است و از پرانتز بیرون می آمد و آنگاه امید ریاضی با منفی خودش جمع می شد و نتیجه نهایی صفر می شد. 
```{admonition} نکته!
:class: note

1)$$Var(X)= \frac{1}{n}  \sum_{i=1}^n (x_{i}-\mu )^2$$  
2)$$S^2= \frac{1}{n-1}  \sum_{i=1}^n X_{i}-\overline{X})^2$$ 
 
شاید شما این دو عبارت را دیده باشید.  
آیا فرمولی اشتباه است؟   
خیر، هر کدام از این فرمول ها برای شرایطی کاربرد دارند.  
فرمول 1 برای زمانیست که واریانس جمعیت را محاسبه میکنیم. که $$\mu$$ میانگین جمعیت بوده و $$n$$ تعداد اعضای جمعیت می باشد.  یعنی شما اطلاعات کل فضای آزمایش را در اختیار دارید.   
فرمول 2 برای زمانیست که با نمونه ایی از جمعیت بزرگ سروکار داریم واریانس نمونه را محاسبه میکنیم. که $$\overline{X}$$ میانگین نمونه بوده و $$n$$ تعداد نمونه می باشد. یعنی شما اطلاعات کل فضای آزمایش را در اختیار ندارید.  
علت ظاهر شدن $$n-1 $$ بدلیل تصحیح بسل است و برای تصحیح سوگیری معرفی شده با تخمین واریانس جامعه از یک نمونه به جای کل جامعه استفاده می شود.
```
### خواص
* $$Var(aX+b) = a^{2}Var(X) $$
اولین سوالی که مطرح میشود این موضوع است که چرا همچون امید ریاضی دیگر b ظاهر نشده است.
دلیل این موضوع این است که تمام متغییر های به یک اندازه و به یک جهت حرکت میکنند. پس میانگین هم به همان اندازه تغییر میکند و در نهایت انگار تغییری رخ نداده و حال چرا ضریب a به صورت توان دو ظاهر شده است بهترین توضیح این است که بگوییم تمام مقادیر a برابر شده اند و همانند b، کل مجموعه به یک سمت حرکت نکرده بلکه مجموعه بنا به اندازه a منبسط یا منقبض شده است پس بنظر میرسد باید اثری از a در واریانس نیز دیده شود.
### انحراف معیار
که با $$\sigma $$ نمایش داده می شود جذر واریانس می باشد.
## کواریانس
کواریانس مفهومی است که به ما قدرت این را میدهد که ثابت کنیم دو متغییر بر یکدیگر تاثیری دارند یا خیر رخ دادن و انجام یکی از آنها تاثیری بر دیگری ندارد.
مثلا می خواهیم بدانیم آیا تک فرزندی ربطی به ارتکاب جرم در بزرگسالی دارد یا خیر.  
ما همیشه دنبال کمّی کردن وقایع هستیم. برای درک وابستگی چند چیز به یکدیگر باید مفهومی ریاضی را تعریف و استفاده کنیم.
تصویر 3
در شکل بالا فرض کنید نمودار توزیع توام دو متغیر رسم شده است و فرض کنید امید ریاضی این دو متغییر نقاطی هستند که در شکل مشخص شده اند.
حال تعریف واریانس را بخاطر بیاورید می خواهیم از آن استفاده کنیم. میگویم اگر نقطه ایی از میانگین X  دور شد و همزمان و در همان جهت از میانگین Y دور شد یک تاثیر مثبتی بگذار و اگر خلاف این رخ داد تاثیر منفی بگذار. به نوعی میگوییم اگر X رشد کرد و Y هم رشد کرد این دو با علامت مثبت ظاهر بشوند و به نوعی دریافت شود که وابستگی دارند و با رشد یکی از آنها در میابیم دیگری نیز رشد کرده است(مثلا افزایش خودرو شخصی شهروندان تهرانی و ترافیک شهر تهران) اگر خلاف این رخ داد یعنی یکی افزایش پیدا کرد و دیگری کاهش یافته و دریافت شود که وابستگی دارند و با رشد یکی، دیگری کاهش میابد(مثلا افزایش فعالیت بدنی و اضافه وزن).
تصویر 4
پس طبق مطلبی که گفته شد می توان نوشت
$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$$
سوالی که مطرح می شود این است که چه زمان کواریانس صفر می شود؟  
تصویر 5
در شکل بالا مشاهده میکنیم نقطه ایی وجود دارد که با رشد متغییر X  و فاصله گرفتن از میانگینش دو برای متغییر Y دو حالت رخ میدهد، یک نقطه(قسمت شمال شرقی) از این تغییر پیروی میکند و افزایش میابد و نقطه دیگر(قسمت جنوب شرقی)خلاف تغییر X عمل می کند و کاهش میابد. پس به نوعی این دو نقطه اثر یکدیگر را خنثی می کنند. و از تعمیم دادن این بررسی به سایر نقاط در میابیم این دو متغییر وابستگی ندارند.
حال ببینیم اگر دو متغییر X و Y مستقل باشند کواریانس آنها چه می شود
$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]= \sum_{y} \sum_{x}(x-E(X))(y-E(Y)) f_{XY}(xy) $$
$$=\sum_{y} \sum_{x}(x-E(X))(y-E(Y)) f_{Y}(y)f_{X}(x)$$
$$=\sum_{y}(y-E(Y)) f_{Y}(y) \sum_{x}(x-E(X))f_{X}(x)$$
$$=\sum_{y}(y-E(Y)) f_{Y}(y) (\sum_{x}xf_{X}(x)-\sum_{x}E(X)f_{X}(x))$$
$$=\sum_{y}(y-E(Y)) f_{Y}(y) (E(X)-E(X))$$
$$=0$$
 پس در میابیم کواریانس دو متغیر مستقل از هم از صفر است.
      
```{admonition} نکته!
:class: note
تاکنون دریافتیم صرفا علامت کواریانس مهم است.
علامت مثبت بیان میکند این دو متغییر تاثیر وابستگی دارند و الگو تغییرشان یکسان است.
علامت منفی بیان می دارد که وابستگی دارند اما کاملا معکوس یکدیگر تغییر میکنند.
و واریانس صفر بیانگر عدم وابستگی است و دو متغییر مستقل هستند.
```
### خواص
* $$Cov(X,X)=Var(X)$$
* $$Cov(X,Y)=Cov(Y,X)$$
* $$Cov(aX+b,Y)=aCov(X,Y)$$
خاصیت آخر نکته جالبی را بیان می کند.
مثلا فرض کنید تاثیر اندازه دور کمر را بر فشار خون بررسی میکنید. حال اگر سایز دور کمر به متر گزارش شود یا به سانتی متر بر کواریانس تاثیر می گذارد.
این موضوع برای ما جالب نیست و دوستداریم فارغ از واحد دو متغیر وابستگی شان بررسی شود.
پس از تکنیک استاندارد کردن استفاده میکنیم
```{admonition} احتیاط!
:class: warning
توجه کنید که در کواریانس صرفا علامت برای ما اهمیت دارد!
```
## همبستگی
حال بیاید متغیر ها را استاندارد کنیم
$$x' = \frac{X-E(X)}{ \sigma_{x} } ,y' = \frac{Y-E(Y)}{ \sigma_{y} }$$
$$ \longrightarrow Cox(X',Y')=\frac{Cov(X,Y)}{ \sigma_{x}\sigma_{y} }$$
که به نتیجه بالا ضریب همبستگی پیرسون یا ضریب همبستگی می گوییم.
به نوعی در استاندارد کردن صورت و مخرج را هم واحد کردیم و از تغییر نتیجه با تغییر واحد جلوگیری کردیم.
```{admonition} نکته!
:class: note
همبستگی همواره عددی بین مثبت یک و منفی یک می باشد هر چقدر دو عدد وابستگی داشته باشند که با رشد یکی دیگری نیز رشد کند به مثبت یک نزدیک می شوند و هر چقدر وابستگی داشته باشند که با رشد یکی دیگری کاهش میابدبه منفی یک نزدیک می شود. و در حالت کلی اگر به مثبت یک یا منفی یک نزدیک شویم رابطه دو متغییر به رابطه خطی نزدیک تر می شودو
اگر صفر باشد یعنی دو متغیر از یکدیگر مستقل اند.
```
```{admonition} نکته!
:class: note
$$Cor(X,X)=1$$
$$Cor(X,-X)=-1$$
```
```{admonition} احتیاط!
:class: warning
توجه کنید لزوما هر زمان که همبستگی یک شد بدین معنا نیست که دو متغییر یکسان هستند، برای مثال:
$$Cor(X+8,X)=1$$
```
## منابع
* [مکتب خونه](https://maktabkhooneh.org/course/%D8%A2%D9%85%D8%A7%D8%B1-%D8%A7%D8%AD%D8%AA%D9%85%D8%A7%D9%84-%D9%85%D9%87%D9%86%D8%AF%D8%B3%DB%8C-mk627/%D9%81%D8%B5%D9%84-%D8%A7%D9%88%D9%84-%D8%A2%D9%85%D8%A7%D8%B1-%D8%A7%D8%AD%D8%AA%D9%85%D8%A7%D9%84-%D9%85%D9%87%D9%86%D8%AF%D8%B3%DB%8C-ch1733/%D9%88%DB%8C%D8%AF%DB%8C%D9%88-%DA%A9%D9%88%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3-%D9%87%D9%85%D8%A8%D8%B3%D8%AA%DA%AF%DB%8C/) 
* https://en.wikipedia.org/wiki/Variance
